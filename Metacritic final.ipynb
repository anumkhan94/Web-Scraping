{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import requests\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to use a user agent here, because metacritics does not accept bots\n",
    "#we are using a tested go-to user agent here, it can be found online\n",
    "#read more about user agents here:\n",
    "#https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter - https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc\n"
     ]
    }
   ],
   "source": [
    "url = input('Enter - ')\n",
    "page = requests.get(url, headers = headers)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "# https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n"
     ]
    }
   ],
   "source": [
    "container = soup.find_all('td', class_ = 'clamp-summary-wrap')\n",
    "print(type(container))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then lets find out how many movies we got\n",
    "len(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Citizen Kane', 'The Godfather', 'Rear Window', 'Casablanca', 'Boyhood', 'Three Colors: Red', 'Vertigo', 'Notorious', \"Singin' in the Rain\", 'City Lights', 'Moonlight', 'Intolerance', 'Pinocchio', 'Touch of Evil', 'The Treasure of the Sierra Madre', \"Pan's Labyrinth\", 'Some Like It Hot', 'North by Northwest', 'Hoop Dreams', 'Rashomon', 'All About Eve', 'Jules and Jim', 'The Wild Bunch', 'My Left Foot', 'The Third Man', 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb', 'Nomadland', 'Gone with the Wind', '4 Months, 3 Weeks and 2 Days', 'Psycho', 'Battleship Potemkin', 'A Streetcar Named Desire', 'American Graffiti', 'Dumbo', 'Roma', 'Ran', 'The Shop Around the Corner', '12 Angry Men', 'Manchester by the Sea', \"Rosemary's Baby\", 'The Maltese Falcon', '12 Years a Slave', 'Killer of Sheep', 'Rocks', 'Nashville', 'Ratatouille', 'Parasite', \"Don't Look Now\", 'The Grapes of Wrath', 'Children of Paradise (1945)']\n"
     ]
    }
   ],
   "source": [
    "movie_names = []\n",
    "movies = container[:50] #here we get the top 50 movies we want\n",
    "movieData = []\n",
    "for movie in movies:\n",
    "    mnameList = []\n",
    "    name = movie.find('h3').text\n",
    "    movie_names.append(name)\n",
    "    movieData.append(mnameList)\n",
    "    mnameList.append(name)\n",
    "print(movie_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-6e321eec7a95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'span'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mmovieDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Genre\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mmovieData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovieDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gen' is not defined"
     ]
    }
   ],
   "source": [
    "#now we need to click into each movie name in order to see detailed information\n",
    "#so we need to extract all the urls\n",
    "movie_names = []\n",
    "movies = container[:50] #here we get the top 50 movies we want\n",
    "movieData = []\n",
    "parentUrl = \"https://www.metacritic.com\"\n",
    "review_links = []\n",
    "    \n",
    "for movie in movies:\n",
    "    movieDict = {}\n",
    "    name = movie.find('h3').text\n",
    "    movie_names.append(name)\n",
    "    \n",
    "    movieDict[\"Movie Name\"] = name\n",
    "#     movieData.append(movieDict)\n",
    "\n",
    "    tag = movie.find('a', class_ = 'title')\n",
    "    link = tag.get('href', None)\n",
    "    \n",
    "    #there are a few different ways to get the links to user reviews\n",
    "    #lets first try to write a loop to open all 50 links of these movies\n",
    "    \n",
    "    detailsLink = parentUrl+link\n",
    "    page = requests.get(detailsLink, headers = headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    tag = soup.find('a', class_ = 'see_all boxed oswald')\n",
    "    review_link = tag.get('href', None)\n",
    "    review_links.append(review_link)\n",
    "    \n",
    "    review_page = requests.get(detailsLink + '/user-reviews', headers = headers)\n",
    "    soup = BeautifulSoup(review_page.content, \"html.parser\")\n",
    "    tag = soup.find_all('div', class_ = 'summary')\n",
    "#     print(len(tag))\n",
    "    top_50 = tag[:50]\n",
    "#     print(len(top_50))\n",
    "    reviewsList = []\n",
    "    for i in range(len(top_50)):\n",
    "        s = top_50[i].text\n",
    "        s = re.sub(r'[^\\w\\s]','',s)\n",
    "        reviewsList.append(s.strip())\n",
    "# print(reviewsList[0])\n",
    "    movieDict[\"Reviews\"] = reviewsList\n",
    "    review_page = requests.get(detailsLink, headers = headers)\n",
    "    soup = BeautifulSoup(review_page.content, \"html.parser\")\n",
    "    genres = soup.find_all('div', class_ = 'genres')\n",
    "    \n",
    "    genres = genres[1:]\n",
    "    \n",
    "    genList = []\n",
    "    for genre in genres:\n",
    "        gen = genre.find('span')\n",
    "        print(gen.text)\n",
    "    movieDict[\"Genre\"] = gen.text\n",
    "    \n",
    "    movieData.append(movieDict)\n",
    "    \n",
    "# print(review_links)\n",
    "# https://www.metacritic.com/movie/citizen-kane-1941\n",
    "# https://www.metacritic.com/movie/citizen-kane-1941/user-reviews\n",
    "print(movieData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "for i in range(len(review_links)):\n",
    "    if not review_links[i].endswith('user-reviews'):\n",
    "        continue\n",
    "    else:\n",
    "        review_page = requests.get('https://www.metacritic.com'+review_links[i], headers = headers)\n",
    "        soup = BeautifulSoup(review_page.content, \"html.parser\")\n",
    "        tag = soup.find_all('div', class_ = 'summary') #find_all to return a list\n",
    "        n = n + 1\n",
    "#         print('Movie', n)\n",
    "        print('Total user reviews:', len(tag))\n",
    "        top_50 = tag[:50]\n",
    "        print(len(top_50))#some of the movies don't have 50 reviews, but that is fine  \n",
    "        print(top_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Movie Name': 'Citizen Kane'}, {'Movie Name': 'The Godfather'}]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "        \n",
    "for i in range(len(review_links)):\n",
    "    review_page = requests.get('https://www.metacritic.com'+review_links[i], headers = headers)\n",
    "    soup = BeautifulSoup(review_page.content, \"html.parser\")\n",
    "    tag = soup.find_all('div', class_ = 'summary')\n",
    "#     print(len(tag))\n",
    "    top_50 = tag[:50]\n",
    "#     print(len(top_50))\n",
    "    reviewsList = []\n",
    "    for i in range(len(top_50)):\n",
    "        s = top_50[i].text\n",
    "        s = re.sub(r'[^\\w\\s]','',s)\n",
    "        reviewsList.append(s.strip())\n",
    "# print(reviewsList[0])\n",
    "    movieData[i][\"Reviews\"] = reviewsList\n",
    "print(movieData[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Data saved to metacritic.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "finalData = []\n",
    "print(len(movieData))\n",
    "for i in range(len(movieData)):\n",
    "    \n",
    "    movieDict = {}\n",
    "    name = movieData[i][0]\n",
    "#     genre = movieData[i][1]\n",
    "    revs = movieData[i][1]\n",
    "    movieDict[\"Movie Name\"] = name\n",
    "#     movieDict[\"Genre\"] = genre\n",
    "    movieDict[\"Reviews\"] = revs\n",
    "    finalData.append(movieDict)\n",
    "# print(movieDict)\n",
    "    \n",
    "csv_file = \"metacritic.csv\"\n",
    "csv_columns = [\"Movie Name\", \"Genre\", \"Reviews\"]\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        count = 1\n",
    "#         print(finalData)\n",
    "        for data in finalData:\n",
    "            writer.writerow(data)\n",
    "#             print(count)\n",
    "            count+=1\n",
    "    print(\"Data saved to metacritic.csv\")\n",
    "\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing data in SQLite\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('meta.db')\n",
    "c = conn.cursor()\n",
    "c.execute('DROP TABLE IF EXISTS movies')\n",
    "c.execute('''CREATE TABLE movies (movie_name text, genre text, review text)''')\n",
    "\n",
    "\n",
    "# load the data into a Pandas DataFrame\n",
    "movies = pd.read_csv('meta.csv')\n",
    "# movies = movies.drop(label)\n",
    "\n",
    "# write the data to a sqlite table\n",
    "# movies.head(2)\n",
    "\n",
    "# for row in movies.iterrows:\n",
    "for index, row in movies.iterrows(): \n",
    "#     print (row[\"Movie Name\"]) \n",
    "    name = row[\"Movie Name\"]\n",
    "    genre = row[\"Genre\"]\n",
    "    review = row[\"Reviews\"]\n",
    "    \n",
    "    c.execute('INSERT INTO movies (movie_name, genre, review) VALUES (?,?,?)',\n",
    "                       (name, genre, review))\n",
    "    conn.commit()\n",
    "    print(name, genre)\n",
    "c.close()\n",
    "conn.close()\n",
    "print(\"Data saved to meta.db\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
